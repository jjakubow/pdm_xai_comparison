{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Performance of Explainable AI methods in Asset Failure Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "import numpy as np\n",
    "import warnings\n",
    "import itertools\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "\n",
    "# models\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from interpret.glassbox import ExplainableBoostingClassifier, ExplainableBoostingRegressor\n",
    "\n",
    "def timeit(method):\n",
    "    def timed(*args, **kw):\n",
    "        ts = time.time()\n",
    "        result = method(*args, **kw)\n",
    "        te = time.time()\n",
    "        print(f'Time elapsed ({method.__name__}): {round(te-ts, 1)} s.')\n",
    "        return result\n",
    "    return timed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DataFrame preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"D:\\Turbofan dataset\\CMaps\\train_FD003.txt\", sep=\" \", header=None)\n",
    "\n",
    "def prepare_df(df, rul_normal, rul_anomaly, limit_rul=False, dropna=False, special_scale=False):\n",
    "    df = df.rename(columns= {0: 'unit', 1: 'cycle'})\n",
    "    df = df.iloc[:, :-2]\n",
    "\n",
    "    # calculate RUL\n",
    "    df_max_cycle = df.groupby(\"unit\").max()['cycle']\n",
    "\n",
    "    print(\"Calculating RUL of each observation\")\n",
    "    for ind in tqdm(df.index.values):\n",
    "        unit = df.loc[ind, \"unit\"]\n",
    "        cycle = df.loc[ind, \"cycle\"]\n",
    "        max_cycle = df_max_cycle.loc[unit]\n",
    "        df.loc[ind, \"RUL\"] = max_cycle - cycle\n",
    "\n",
    "    df.columns = [\"unit\", \"cycle\"] + [f\"Setting {i}\" for i in range(1, 4)] +  [f\"Measurement {i}\" for i in range(1, 22)] + [\"RUL\"]\n",
    "    df[\"RUL_binary\"] = df[\"RUL\"].apply(lambda x: 0 if x >= rul_normal else 1 if x <= rul_anomaly else None)\n",
    "\n",
    "    if limit_rul:\n",
    "        df[\"RUL\"] = df[\"RUL\"].apply(lambda x: min(x, rul_normal))\n",
    "\n",
    "    if dropna:\n",
    "        df = df.dropna()\n",
    "    \n",
    "    if special_scale:\n",
    "        new_df = pd.DataFrame()\n",
    "        feature_columns = [i for i in df.columns if \"Setting\" in i or \"Measurement\" in i]\n",
    "        for unit in df[\"unit\"].unique():\n",
    "            df_unit = df.loc[(df[\"unit\"] == unit)]\n",
    "            df_unit_normal = df_unit.loc[df_unit[\"cycle\"] <= 50]\n",
    "            scaler = MinMaxScaler()\n",
    "            scaler.fit(df_unit_normal[feature_columns])\n",
    "            df_unit[feature_columns] = scaler.transform(df_unit[feature_columns])\n",
    "            new_df = new_df.append(df_unit)\n",
    "        \n",
    "        new_df = new_df.loc[new_df[\"cycle\"] > 50]\n",
    "        return new_df\n",
    "                \n",
    "\n",
    "    return df\n",
    "\n",
    "df = prepare_df(df, rul_normal=130, rul_anomaly=40, limit_rul=True, dropna=False, special_scale=True)\n",
    "\n",
    "id_column = \"unit\"\n",
    "X_columns = [i for i in df.columns if \"Setting\" in i or \"Measurement\" in i]\n",
    "y_column = [\"RUL\"]\n",
    "rul_column = [\"RUL\"]\n",
    "\n",
    "id_array = df[id_column].values\n",
    "X_array = df[X_columns].values\n",
    "y_array = df[y_column].values\n",
    "rul_array = df[rul_column].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(np.unique(y_array)) <= 2:\n",
    "    classification = True\n",
    "else:\n",
    "    classification = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Hyperparameters tuning / model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import copy\n",
    "\n",
    "def cv_train_model(ids, X, y, model, n_folds, verbose=True, classification=True):\n",
    "    \"\"\" Function which trains the model using cross-validation method\"\"\"\n",
    "   \n",
    "    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    accuracies = []\n",
    "    for train_ids, test_ids in kf.split(np.unique(ids)):\n",
    "        bool_train = np.isin(ids, train_ids)\n",
    "        bool_test = np.isin(ids, test_ids)\n",
    "        \n",
    "        ids_train, X_train, y_train = ids[bool_train], X[bool_train], y[bool_train]\n",
    "        ids_test, X_test, y_test = ids[bool_test], X[bool_test], y[bool_test]\n",
    "        \n",
    "        try:\n",
    "            model.fit(X_train, y_train)\n",
    "        except Exception as e:\n",
    "            print(X_train.shape, y_train.shape)\n",
    "            print(X_train[0])\n",
    "            raise ValueError(\"Error during model fitting : %s\" % e)\n",
    "        \n",
    "        y_pred = model.predict(X_test)\n",
    "        if classification:\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "        else:\n",
    "            # accuracy = r2_score(y_test, y_pred)\n",
    "            accuracy = -np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    mean_acc = np.mean(accuracies)\n",
    "    if verbose:\n",
    "        print(\"Mean accuracy =\", round(mean_acc, 3))\n",
    "        \n",
    "    return mean_acc\n",
    "\n",
    "def grid_search(ids, X, y, model_class, search_space_dict, n_folds):\n",
    "    search_space = list(itertools.product(*search_space_dict.values()))\n",
    "    param_dict = {}\n",
    "    best_params = {}\n",
    "    best_acc = -1000\n",
    "    for params in tqdm(search_space, colour=\"red\"):\n",
    "        for k, v in zip(search_space_dict.keys(), params):\n",
    "            param_dict[k] = v\n",
    "        \n",
    "        classification = len(np.unique(y_array)) <= 2\n",
    "        \n",
    "        model = model_class(**param_dict)\n",
    "        acc = cv_train_model(id_array, X_array, y_array, model, 5, verbose=False, classification=classification)\n",
    "        if acc > best_acc:\n",
    "            best_params = copy.deepcopy(param_dict)\n",
    "            best_acc = acc\n",
    "\n",
    "            print(\"Best params so far: %s (acc_score = %.3f)\" % (best_params, best_acc))\n",
    "            \n",
    "    return best_params, best_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if classification:\n",
    "    # classification\n",
    "    print(\"Running classification task...\")\n",
    "    search_space_dict = {\"n_estimators\": [32, 64, 128, 256], \n",
    "                         \"max_depth\": [4, 8, 12],\n",
    "                         \"learning_rate\": [0.01, 0.1, 0.2, 0.3, 0.5],\n",
    "                         \"objective\": [\"binary:logistic\", \"binary:logitraw\", \"binary:hinge\"],\n",
    "                         \"verbosity\": [0]\n",
    "                         }\n",
    "    params, score = grid_search(id_array, X_array, y_array, XGBClassifier, search_space_dict, 4)\n",
    "    print(f\"XGBoost Classifier: \\n  params: {params}\\n  score: {round(score, 3)}\")\n",
    "    \n",
    "else:\n",
    "    # regression\n",
    "    print(\"Running regression task...\")\n",
    "    search_space_dict = { \"n_estimators\": [8, 16, 32, 64, 128], \n",
    "                         \"max_depth\": [6, 9],\n",
    "                         \"learning_rate\": [0.01, 0.1, 0.2, 0.3, 0.5],\n",
    "                         \"objective\": [\"reg:squarederror\"],\n",
    "                         \"verbosity\": [0]\n",
    "                     }\n",
    "    params, score = grid_search(id_array, X_array, y_array, XGBRegressor, search_space_dict, 4)\n",
    "    print(f\"XGBoost Regressor: \\n  params: {params}\\n  score: {round(score, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if classification:\n",
    "    # classification\n",
    "    print(\"Running classification task...\")\n",
    "    search_space_dict = {\"n_estimators\": [8, 16, 32, 64], \n",
    "                     \"max_depth\": [2, 4, 8],\n",
    "                     \"criterion\": [\"gini\", \"entropy\"],\n",
    "                     \"min_samples_leaf\": [2, 4, 8]\n",
    "                     }\n",
    "    params, score = grid_search(id_array, X_array, y_array, RandomForestClassifier, search_space_dict, 5)\n",
    "    print(f\"XGBoost Classifier: \\n  params: {params}\\n  score: {round(score, 3)}\")\n",
    "    \n",
    "else:\n",
    "    # regression\n",
    "    print(\"Running regression task...\")\n",
    "    search_space_dict = {\"n_estimators\": [8, 16, 32, 64, 128], \n",
    "                    \"max_depth\": [6, 9, 12],\n",
    "                    \"criterion\": [\"mse\"],\n",
    "                    \"min_samples_leaf\": [4, 8, 16]\n",
    "                     }\n",
    "    params, score = grid_search(id_array, X_array, y_array, RandomForestRegressor, search_space_dict, 4)\n",
    "    print(f\"Random Forest Regressor: \\n  params: {params}\\n  score: {round(score, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if classification:\n",
    "    # classification\n",
    "    print(\"Running classification task...\")\n",
    "    search_space_dict = {'C': [10, 100], \n",
    "                     'gamma': [1, 0.1, 0.01],\n",
    "                     'kernel': ['rbf', 'poly']}\n",
    "    params, score = grid_search(id_array, X_array, y_array, SVC, search_space_dict, 4)\n",
    "    print(f\"XGBoost Classifier: \\n  params: {params}\\n  score: {round(score, 3)}\")\n",
    "    \n",
    "else:\n",
    "    # regression\n",
    "    print(\"Running regression task...\")\n",
    "    search_space_dict = {'C': [0.1, 1, 10, 100], \n",
    "                     'gamma': [1, 0.1, 0.01, 0.001],\n",
    "                     'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "    search_space_dict = {'C': [1, 10, 100, 200], \n",
    "                     'gamma': ['scale'],\n",
    "                     'kernel': ['rbf', 'poly', 'sigmoid']}\n",
    "    params, score = grid_search(id_array, X_array, y_array, SVR, search_space_dict, 4)\n",
    "    print(f\"SVR: \\n  params: {params}\\n  score: {round(score, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if classification:\n",
    "    # classification\n",
    "    print(\"Running classification task...\")\n",
    "    search_space_dict = {\"activation\": [\"tanh\", \"relu\", \"logistic\"],\n",
    "                     \"hidden_layer_sizes\": [(60,), (60, 30), (60, 30, 20), (30, ), (30, 20), (30, 20, 15)], \n",
    "                     \"batch_size\": [16, 32], \n",
    "                     \"max_iter\": [25]\n",
    "}\n",
    "    params, score = grid_search(id_array, X_array, y_array, MLPClassifier, search_space_dict, 4)\n",
    "    print(f\"XGBoost Classifier: \\n  params: {params}\\n  score: {round(score, 3)}\")\n",
    "    \n",
    "else:\n",
    "    # regression\n",
    "    print(\"Running regression task...\")\n",
    "    search_space_dict = {\"activation\": [\"tanh\", \"relu\", \"logistic\"],\n",
    "                     \"hidden_layer_sizes\": [(60,), (60, 30), (60, 30, 20), (30, ), (30, 20), (30, 20, 15)], \n",
    "                     \"batch_size\": [16, 32], \n",
    "                     \"max_iter\": [25]\n",
    "}\n",
    "    params, score = grid_search(id_array, X_array, y_array, MLPRegressor, search_space_dict, 4)\n",
    "    print(f\"MLP Regressor: \\n  params: {params}\\n  score: {round(score, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explainable Boosting Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if classification:\n",
    "    # classification\n",
    "    print(\"Running classification task...\")\n",
    "    search_space_dict = {\"max_bins\": [64, 128, 256], \n",
    "                       \"min_samples_leaf\": [2, 4, 8],\n",
    "                       \"max_leaves\": [2, 3, 4],\n",
    "                       \"learning_rate\": [0.001, 0.01, 0.1],\n",
    "}\n",
    "    params, score = grid_search(id_array, X_array, y_array, ExplainableBoostingClassifier, search_space_dict, 5)\n",
    "    print(f\"XGBoost Classifier: \\n  params: {params}\\n  score: {round(score, 3)}\")\n",
    "    \n",
    "else:\n",
    "    # regression\n",
    "    print(\"Running regression task...\")\n",
    "    search_space_dict = {\"max_bins\": [64, 128, 256], \n",
    "                       \"min_samples_leaf\": [2, 4, 8],\n",
    "                       \"learning_rate\": [0.001, 0.01, 0.1],\n",
    "}\n",
    "    params, score = grid_search(id_array, X_array, y_array, ExplainableBoostingRegressor, search_space_dict, 5)\n",
    "    print(f\"XGBoost Regressor: \\n  params: {params}\\n  score: {round(score, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refit with best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids, test_ids = train_test_split(np.unique(id_array), test_size=0.2, random_state=42)\n",
    "\n",
    "bool_train = np.isin(id_array, train_ids)\n",
    "bool_test = np.isin(id_array, test_ids)\n",
    "\n",
    "ids_train, X_train, y_train, rul_train = id_array[bool_train], X_array[bool_train], y_array[bool_train], rul_array[bool_train]\n",
    "ids_test, X_test, y_test, rul_test = id_array[bool_test], X_array[bool_test], y_array[bool_test], rul_array[bool_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fitted_model(model_class, model_params, model_name, X_train, y_train, save=False):\n",
    "    time_start = time.time()\n",
    "    model = model_class(**model_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    time_end = time.time()\n",
    "    print(\"%s training finished in %.1f seconds.\" % (model_name, time_end - time_start))\n",
    "\n",
    "    return model\n",
    "\n",
    "if classification:\n",
    "    # NOTE: INVALID HYPERPARAMTERS -> THESE WERE USED FOR REGRESSION, RECALCULATE IF NEEDED\n",
    "    xgboost_params = {'n_estimators': 64, 'max_depth': 9, 'learning_rate': 0.1, 'objective': 'reg:squarederror', 'verbosity': 0}\n",
    "    # xgboost_params  = {'n_estimators': 252, 'max_depth': 12, 'learning_rate': 0.5, 'objective': 'reg:squarederror', 'verbosity': 0}\n",
    "    xgboost_model = get_fitted_model(XGBClassifier, xgboost_params, \"XGBoost\", X_train, y_train)\n",
    "\n",
    "    rf_params = {'n_estimators': 128, 'max_depth': 12, 'criterion': 'mse', 'min_samples_leaf': 4}\n",
    "    rf_model = get_fitted_model(RandomForestClassifier, rf_params, \"Random Forest\", X_train, y_train)\n",
    "\n",
    "    svm_params = {'C': 100, 'gamma': 1, 'kernel': 'poly'}\n",
    "    svm_model = get_fitted_model(SVC, svm_params, \"Support Vector Machine\", X_train, y_train)\n",
    "\n",
    "    mlp_params = {'activation': 'relu', 'hidden_layer_sizes': (30, 20, 15), 'batch_size': 16, 'max_iter': 25}\n",
    "    mlp_model = get_fitted_model(MLPClassifier, mlp_params, \"Multi-Layer Perceptron\", X_train, y_train)\n",
    "\n",
    "    ebm_params = {\"feature_names\": X_columns, \"interactions\": 0}\n",
    "    ebm = get_fitted_model(ExplainableBoostingClassifier, ebm_params, \"Explainable Boosting Machine\", X_train, y_train)\n",
    "\n",
    "else:\n",
    "    xgboost_params = {'n_estimators': 64, 'max_depth': 6, 'learning_rate': 0.1, 'objective': 'reg:squarederror', 'verbosity': 0}\n",
    "    xgboost_model = get_fitted_model(XGBRegressor, xgboost_params, \"XGBoost Reg\", X_train, y_train)\n",
    "\n",
    "    rf_params = {'n_estimators': 64, 'max_depth': 12, 'criterion': 'mse', 'min_samples_leaf': 4, }\n",
    "    rf_model = get_fitted_model(RandomForestRegressor, rf_params, \"Random Forest\", X_train, y_train)\n",
    "\n",
    "    # svm_params = {'C': 100, 'gamma': 1.0, 'kernel': 'poly',}\n",
    "    svm_params = {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
    "    svm_model = get_fitted_model(SVR, svm_params, \"Support Vector Machine\", X_train, y_train)\n",
    "\n",
    "    mlp_params = {'activation': 'relu', 'hidden_layer_sizes': (60, 30, 20), 'batch_size': 16, 'max_iter': 25}\n",
    "    mlp_model = get_fitted_model(MLPRegressor, mlp_params, \"Multi-Layer Perceptron\", X_train, y_train)\n",
    "\n",
    "    ebm_params = {\"feature_names\": X_columns, \"interactions\": 0, }\n",
    "    ebm = get_fitted_model(ExplainableBoostingRegressor, ebm_params, \"Explainable Boosting Machine\", X_train, y_train)\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for name, model in zip([\"xgboost\", \"rf\", \"svm\", \"mlp\", \"ebm\"], [xgboost_model, rf_model, svm_model, mlp_model, ebm]):\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    if classification:\n",
    "        print(name)\n",
    "        print(classification_report(y_pred, y_test, digits=3))\n",
    "        print(\"-------------------------------------------------------------\")\n",
    "        \n",
    "    else:\n",
    "        rmse = np.sqrt(mean_squared_error(y_pred, y_test))\n",
    "        print(\"%s: R2 = %.3f, RMSE=%.1f\" % (name, r2_score(y_pred, y_test), rmse))\n",
    "\n",
    "        plt.figure()\n",
    "        plt.title(name)\n",
    "        plt.scatter(y_test, y_pred, s=3, alpha=0.3)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XAI models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from interpret.blackbox import ShapKernel, LimeTabular\n",
    "from interpret import show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# limit number of units used for explanations\n",
    "np.random.seed(42)\n",
    "n_explain_ids = 10\n",
    "ids_explain = np.random.choice(np.unique(ids_test), size=n_explain_ids, replace=False)\n",
    "\n",
    "bool_explain = np.isin(ids_test, ids_explain)\n",
    "ids_explain = ids_test[bool_explain]\n",
    "X_explain = X_test[bool_explain]\n",
    "y_explain = y_test[bool_explain]\n",
    "rul_explain = rul_test[bool_explain]\n",
    "df_explain = pd.DataFrame(data=X_explain, columns=X_columns)         \n",
    "df_explain_sample = df_explain.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build data for explanations -> only failure samples\n",
    "df_explain_sample = df_explain.sample(50)\n",
    "\n",
    "# we are only explaining data of malfunctioning equipment\n",
    "only_class_1 = y_explain < 130\n",
    "df_explain_1 = df_explain[only_class_1]\n",
    "y_explain_1 = y_explain[only_class_1]\n",
    "rul_explain_1 = rul_explain[only_class_1]\n",
    "ids_explain_1 = ids_explain.reshape((-1, 1))[only_class_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_from_explanation(explanation):\n",
    "    feature_names = explanation[\"names\"]\n",
    "    feature_values = explanation[\"values\"]\n",
    "    explain_scores = explanation[\"scores\"]\n",
    "    actual_output = explanation[\"perf\"][\"actual\"]\n",
    "    predicted_output = explanation[\"perf\"][\"predicted\"]\n",
    "    \n",
    "    data = pd.DataFrame(data=[feature_names, feature_values, explain_scores])#, columns=[\"Feature\", \"Value\", \"Explain_Score\"])\n",
    "    data = pd.DataFrame(data={\"Feature\": feature_names, \"Value\": feature_values, \"Explain_Score\": explain_scores, })\n",
    "    data[\"output_actual\"] = actual_output\n",
    "    data[\"output_predicted\"] = predicted_output\n",
    "    data[\"abs_explain_score\"] = abs(data[\"Explain_Score\"])\n",
    "    data = data.sort_values(by=\"abs_explain_score\", ascending=False)\n",
    "    data[\"Rank\"] = np.arange(len(data)) + 1\n",
    "    \n",
    "    return data\n",
    "\n",
    "def generate_local_explanations(explainer, df, y, ids, rul):\n",
    "    local_explanations = explainer.explain_local(df, y)\n",
    "    \n",
    "    explanations = pd.DataFrame()\n",
    "    for i, (_id, _rul) in tqdm(enumerate(zip(ids, rul)), total=rul.shape[0]):   \n",
    "        data_explain = extract_data_from_explanation(local_explanations.data(i))\n",
    "        data_explain[\"unit\"] = _id\n",
    "        data_explain[\"RUL\"] = _rul\n",
    "\n",
    "        explanations = explanations.append(data_explain)\n",
    "\n",
    "    explanations = explanations.reset_index(drop=True)\n",
    "    return explanations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Blackbox models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blackbox_models = {\n",
    "    \"xgb\": xgboost_model, \n",
    "    \"rf\": rf_model, \n",
    "   \"svm\": svm_model, \n",
    "   \"mlp\": mlp_model,\n",
    "}\n",
    "\n",
    "for name, model in blackbox_models.items():\n",
    "    shap_kernel = ShapKernel(model.predict, df_explain_sample)\n",
    "    lime_tabular = LimeTabular(model.predict, df_explain_sample, n_jobs=6, explain_kwargs={\"num_features\": len(X_columns), \"num_samples\": 1500}, \n",
    "                              mode='regression')\n",
    "    blackbox_explainers = {\n",
    "        \"shap\": shap_kernel, \n",
    "        \"lime\": lime_tabular\n",
    "    } \n",
    "    \n",
    "    for exp_name, explainer in blackbox_explainers.items():\n",
    "        time_start = time.time()\n",
    "        timestamp = datetime.today().strftime(\"%m%d-%H%M\")\n",
    "        print(\"Explaining %s with %s... (%s)\" % (name, exp_name, timestamp))\n",
    "        \n",
    "        explanations = generate_local_explanations(explainer, df_explain_1, y_explain_1, ids_explain_1, rul_explain_1)\n",
    "        time_end = time.time()\n",
    "        explanations.to_csv(rf\"results/{name}_{exp_name}_explanations_{timestamp}.csv\")\n",
    "        print(\"Explanations finished in %.1f seconds.\" % (time_end - time_start))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Explanations for EBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "print(\"Explaining ebm\")\n",
    "timestamp = datetime.today().strftime(\"%m%d-%H%M\")\n",
    "explanations = generate_local_explanations(ebm, df_explain_1, y_explain_1, ids_explain_1, rul_explain_1)\n",
    "time_end = time.time()\n",
    "explanations.to_csv(rf\"results/ebm_explanations_{timestamp}.csv\")\n",
    "print(\"Explanations finished in %.1f seconds.\" % (time_end - time_start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
